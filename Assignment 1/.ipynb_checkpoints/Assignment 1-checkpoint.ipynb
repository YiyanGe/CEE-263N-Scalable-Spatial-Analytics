{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.io\n",
    "import math\n",
    "import json\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline  \n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def frange(start, stop, step):\n",
    "    i = start\n",
    "    while i < stop:\n",
    "        yield i\n",
    "        i += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/tweets_1M.json','r') as f:\n",
    "    tweets = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array([[tweets[x]['lat'],tweets[x]['lng']] for x in range(0, len(tweets))])\n",
    "#100K subset\n",
    "sample = 100000\n",
    "total = len(X)\n",
    "subset = X[0::int(total/sample)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1.1 K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-fa543cb8f5eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mt_km\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# start clustering!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mk_means\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m## get the time to finish clustering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mt_fin_km\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_km\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yiyange/anaconda/lib/python3.5/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    819\u001b[0m                 \u001b[0mprecompute_distances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecompute_distances\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m                 \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 n_jobs=self.n_jobs)\n\u001b[0m\u001b[1;32m    822\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yiyange/anaconda/lib/python3.5/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mk_means\u001b[0;34m(X, n_clusters, init, precompute_distances, n_init, max_iter, verbose, tol, random_state, copy_x, n_jobs, return_n_iter)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mprecompute_distances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecompute_distances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 x_squared_norms=x_squared_norms, random_state=random_state)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0;31m# determine if these results are the best so far\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbest_inertia\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minertia\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_inertia\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yiyange/anaconda/lib/python3.5/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36m_kmeans_single\u001b[0;34m(X, n_clusters, x_squared_norms, max_iter, init, verbose, random_state, tol, precompute_distances)\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;31m# init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     centers = _init_centroids(X, n_clusters, init, random_state=random_state,\n\u001b[0;32m--> 432\u001b[0;31m                               x_squared_norms=x_squared_norms)\n\u001b[0m\u001b[1;32m    433\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initialization complete\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yiyange/anaconda/lib/python3.5/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36m_init_centroids\u001b[0;34m(X, k, init, random_state, x_squared_norms, init_size)\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'k-means++'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m         centers = _k_init(X, k, random_state=random_state,\n\u001b[0;32m--> 640\u001b[0;31m                           x_squared_norms=x_squared_norms)\n\u001b[0m\u001b[1;32m    641\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'random'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0mseeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yiyange/anaconda/lib/python3.5/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36m_k_init\u001b[0;34m(X, n_clusters, x_squared_norms, random_state, n_local_trials)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mbest_pot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mbest_dist_sq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrial\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_local_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0;31m# Compute potential when including center candidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             new_dist_sq = np.minimum(closest_dist_sq,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# use this to get a n (that is close to 60 secs)\n",
    "n = 370\n",
    "## initialize with K-means++, a good way of speeding up convergence\n",
    "k_means = KMeans(init='k-means++', n_clusters=n, n_init=10)\n",
    "## record the current time\n",
    "t_km = time.time()\n",
    "# start clustering!\n",
    "k_means.fit(X)\n",
    "## get the time to finish clustering\n",
    "t_fin_km = time.time() - t_km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t_fin_km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing n equal to 35\n",
      "54.9270977973938\n",
      "testing n equal to 36\n",
      "60.50568079948425\n"
     ]
    }
   ],
   "source": [
    "#detect maximum k\n",
    "# start with relatively reasonable n \n",
    "n = 35\n",
    "t_fin_km = 0\n",
    "while t_fin_km <= 60:\n",
    "    print ('testing n equal to ' + str(n))\n",
    "    ## initialize with K-means++, a good way of speeding up convergence\n",
    "    k_means = KMeans(init='k-means++', n_clusters=n, n_init=10)\n",
    "    ## record the current time\n",
    "    t_km = time.time()\n",
    "    # start clustering!\n",
    "    k_means.fit(X)\n",
    "    ## get the time to finish clustering\n",
    "    t_fin_km = time.time() - t_km\n",
    "    #\n",
    "    print (t_fin_km)\n",
    "    n += 1\n",
    "\n",
    "#print (t_fin_km)\n",
    "# max k = 380    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_means_labels = k_means.labels_\n",
    "k_means_cluster_centers = k_means.cluster_centers_\n",
    "k_means_labels_unique = np.unique(k_means_labels)\n",
    "ft = (k_means_labels, k_means_cluster_centers, k_means_labels_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1.2 MiniBatch k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "950 38.39891600608826\n",
      "1050 42.738019943237305\n",
      "1150 44.84724998474121\n",
      "1250 55.631016969680786\n",
      "1350 60.259560108184814\n"
     ]
    }
   ],
   "source": [
    "n = 850\n",
    "perc = 0.01\n",
    "t_mini_batch = 0\n",
    "batch_size=int(len(X)*perc)\n",
    "while t_mini_batch <= 60:\n",
    "    mbk = MiniBatchKMeans(init='k-means++', n_clusters=n, batch_size=batch_size,\n",
    "                          n_init=10, max_no_improvement=10, verbose=0)\n",
    "    t0 = time.time()\n",
    "    mbk.fit(X)\n",
    "    t_mini_batch = time.time() - t0\n",
    "    n += 100\n",
    "    print (n, t_mini_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# picked a relatively ideal perc based on previous calculation; not entirely sure why...\n",
    "for perc in [0.1]:\n",
    "    print ('perc is '+ str(perc))\n",
    "    batch_size=int(len(X)*perc)\n",
    "    n = 100\n",
    "    t_mini_batch = 0\n",
    "    while t_mini_batch <= 60:\n",
    "        print ('testing n equal to ' + str(n))\n",
    "        mbk = MiniBatchKMeans(init='k-means++', n_clusters=n, batch_size=batch_size,\n",
    "                            n_init=10, max_no_improvement=10, verbose=0)\n",
    "        t0 = time.time()\n",
    "        mbk.fit(X)\n",
    "        t_mini_batch = time.time() - t0\n",
    "        n += 10\n",
    "        print (t_mini_batch)\n",
    "# max n = 1490"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mbk_means_labels = mbk.labels_\n",
    "mbk_means_cluster_centers = mbk.cluster_centers_\n",
    "mbk_means_labels_unique = np.unique(mbk_means_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "part 1.3 DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import utm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for n in range(0, len(X)):\n",
    "    meters = utm.from_latlon(X[n][0],X[n][1])\n",
    "    X[n][0] = meters[0]\n",
    "    X[n][1] = meters[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#recordedtime = {}\n",
    "ncluster = {}\n",
    "for eps in frange(0.0005, 0.004, 0.0005):\n",
    "    \n",
    "    t_db = time.time()\n",
    "    db = DBSCAN(eps=eps, min_samples=100).fit(X)\n",
    "    t_fin_db = time.time() - t_db\n",
    "    \n",
    "    db_labels = db.labels_\n",
    "    core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "    core_samples_mask[db.core_sample_indices_] = True\n",
    "    n_clusters_ = len(set(db_labels)) - (1 if -1 in db_labels else 0)\n",
    "    ncluster[eps] = n_clusters_\n",
    "    #db_labels_unique = np.unique(db_labels)\n",
    "    #recordedtime[eps] = t_fin_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t_db = time.time()\n",
    "db = DBSCAN(eps=0.001, min_samples=100).fit(X_meter)\n",
    "t_fin_db = time.time() - t_db\n",
    "\n",
    "#array of numbers, one number represents one cluster\n",
    "db_labels = db.labels_\n",
    "db_labels_unique = set(db_labels)\n",
    "# minus if there are unclustered noises\n",
    "n_clusters_ = len(set(db_labels)) - (1 if -1 in db_labels else 0)\n",
    "db_labels_unique = np.unique(db_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array([[tweets[x]['lat'],tweets[x]['lng']] for x in range(0, len(tweets))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get colors and plot all the points, color-coded by cluster (or gray if not in any cluster, aka noise)\n",
    "fig, ax = plt.subplots(figsize=[8,10])\n",
    "ax.set_xlim([-130, -112])\n",
    "ax.set_ylim([32, 44])\n",
    "colors = plt.cm.rainbow(np.linspace(0, 1, len(db_labels_unique)))\n",
    "\n",
    "# for each cluster label and color, plot the cluster's points\n",
    "for db_label, color in zip(db_labels_unique, colors):\n",
    "    \n",
    "    size = 10\n",
    "    if db_label == -1: #make the noise (which is labeled -1) appear as smaller gray points\n",
    "        color = 'gray'\n",
    "        size = 3\n",
    "        alpha=0.01\n",
    "    \n",
    "    # plot the points that match the current cluster label\n",
    "    x_coords = X[db_labels==db_label][:,1]\n",
    "    y_coords = X[db_labels==db_label][:,0]\n",
    "    ax.scatter(x=x_coords, y=y_coords, c=color, edgecolor='', s=size, alpha=0.5)\n",
    "\n",
    "ax.set_title('Number of clusters: {}'.format(n_clusters_)) #string concatenation\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2. Clustering: Scalability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "records = {}\n",
    "for n in range(100, 100100, 100):\n",
    "    \n",
    "    sample = n\n",
    "    total = len(X)\n",
    "    subset = X[0::int(total/sample)]\n",
    "    \n",
    "    ## initialize with K-means++, a good way of speeding up convergence\n",
    "    k_means = KMeans(init='k-means++', n_clusters=100, n_init=10)\n",
    "    ## record the current time\n",
    "    t_km = time.time()\n",
    "    # start clustering!\n",
    "    k_means.fit(subset)\n",
    "    ## get the time to finish clustering\n",
    "    t_fin_km = time.time() - t_km\n",
    "    \n",
    "    records[sample] = t_fin_km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "records_df = pd.DataFrame.from_dict(records, orient = 'index')\n",
    "records_df.to_csv('data/part2_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[8,10])\n",
    "ax.scatter(x=list(records.keys()), y=list(records.values()))\n",
    "#plt.savefig('part2.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#K-means....need to rerun\n",
    "#Number of requested clusters k (consider the range of 2 to the k_max)\n",
    "k_max = 380\n",
    "records = {}\n",
    "for n in range(2, k_max+1):\n",
    "\n",
    "    ## initialize with K-means++, a good way of speeding up convergence\n",
    "    k_means = KMeans(init='k-means++', n_clusters=n, n_init=10)\n",
    "    ## record the current time\n",
    "    t_km = time.time()\n",
    "    # start clustering!\n",
    "    k_means.fit(X)\n",
    "    ## get the time to finish clustering\n",
    "    t_fin_km = time.time() - t_km\n",
    "    \n",
    "    records[n] = t_fin_km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "records_df = pd.DataFrame.from_dict(records, orient = 'index')\n",
    "records_df.to_csv('data/part2_1_b_Kmeans.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[8,10])\n",
    "ax.scatter(x=list(records.keys()), y=list(records.values()))\n",
    "#plt.savefig('part2_.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mini batch k_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin 2000\n",
      "begin 3000\n",
      "begin 4000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiyange/anaconda/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1300: RuntimeWarning: init_size=3 should be larger than k=100. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "/Users/yiyange/anaconda/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1300: RuntimeWarning: init_size=6 should be larger than k=100. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "begin 5000\n",
      "begin 6000\n",
      "begin 7000\n",
      "begin 8000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiyange/anaconda/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1300: RuntimeWarning: init_size=9 should be larger than k=100. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "/Users/yiyange/anaconda/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1300: RuntimeWarning: init_size=12 should be larger than k=100. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "begin 9000\n",
      "begin 10000\n",
      "begin 11000\n",
      "begin 12000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiyange/anaconda/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1300: RuntimeWarning: init_size=15 should be larger than k=100. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "/Users/yiyange/anaconda/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1300: RuntimeWarning: init_size=18 should be larger than k=100. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "begin 13000\n",
      "begin 14000\n",
      "begin 15000\n",
      "begin 16000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiyange/anaconda/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1300: RuntimeWarning: init_size=21 should be larger than k=100. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "/Users/yiyange/anaconda/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1300: RuntimeWarning: init_size=24 should be larger than k=100. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "begin 17000\n",
      "begin 18000\n",
      "begin 19000\n",
      "begin 20000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiyange/anaconda/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1300: RuntimeWarning: init_size=27 should be larger than k=100. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "/Users/yiyange/anaconda/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1300: RuntimeWarning: init_size=30 should be larger than k=100. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "begin 21000\n",
      "begin 22000\n",
      "begin 23000\n",
      "begin 24000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiyange/anaconda/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1300: RuntimeWarning: init_size=33 should be larger than k=100. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "/Users/yiyange/anaconda/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1300: RuntimeWarning: init_size=36 should be larger than k=100. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "begin 25000\n",
      "begin 26000\n",
      "begin 27000\n",
      "begin 28000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiyange/anaconda/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1300: RuntimeWarning: init_size=39 should be larger than k=100. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "/Users/yiyange/anaconda/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1300: RuntimeWarning: init_size=42 should be larger than k=100. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "begin 29000\n",
      "begin 30000\n",
      "begin 31000\n",
      "begin 32000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiyange/anaconda/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1300: RuntimeWarning: init_size=45 should be larger than k=100. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "/Users/yiyange/anaconda/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1300: RuntimeWarning: init_size=48 should be larger than k=100. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "begin 33000\n",
      "begin 34000\n",
      "begin 35000\n",
      "begin 36000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiyange/anaconda/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1300: RuntimeWarning: init_size=51 should be larger than k=100. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "/Users/yiyange/anaconda/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1300: RuntimeWarning: init_size=54 should be larger than k=100. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "begin 37000\n",
      "begin 38000\n",
      "begin 39000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiyange/anaconda/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1300: RuntimeWarning: init_size=57 should be larger than k=100. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "/Users/yiyange/anaconda/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1300: RuntimeWarning: init_size=60 should be larger than k=100. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "begin 40000\n",
      "begin 41000\n",
      "begin 42000\n",
      "begin 43000\n",
      "begin 44000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiyange/anaconda/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1300: RuntimeWarning: init_size=63 should be larger than k=100. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "/Users/yiyange/anaconda/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1300: RuntimeWarning: init_size=66 should be larger than k=100. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "begin 45000\n",
      "begin 46000\n",
      "begin 47000\n",
      "begin 48000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiyange/anaconda/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1300: RuntimeWarning: init_size=69 should be larger than k=100. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "/Users/yiyange/anaconda/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1300: RuntimeWarning: init_size=75 should be larger than k=100. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "begin 49000\n",
      "begin 50000\n",
      "begin 51000\n",
      "begin 52000\n",
      "begin 53000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiyange/anaconda/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1300: RuntimeWarning: init_size=78 should be larger than k=100. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "/Users/yiyange/anaconda/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1300: RuntimeWarning: init_size=81 should be larger than k=100. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "begin 54000\n",
      "begin 55000\n",
      "begin 56000\n",
      "begin 57000\n",
      "begin 58000\n",
      "begin 59000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiyange/anaconda/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1300: RuntimeWarning: init_size=87 should be larger than k=100. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "/Users/yiyange/anaconda/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1300: RuntimeWarning: init_size=93 should be larger than k=100. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "begin 60000\n",
      "begin 61000\n",
      "begin 62000\n",
      "begin 63000\n",
      "begin 64000\n",
      "begin 65000\n",
      "begin 66000\n",
      "begin 67000\n",
      "begin 68000\n",
      "begin 69000\n",
      "begin 70000\n",
      "begin 71000\n",
      "begin 72000\n",
      "begin 73000\n",
      "begin 74000\n",
      "begin 75000\n",
      "begin 76000\n",
      "begin 77000\n",
      "begin 78000\n",
      "begin 79000\n",
      "begin 80000\n",
      "begin 81000\n",
      "begin 82000\n",
      "begin 83000\n",
      "begin 84000\n",
      "begin 85000\n",
      "begin 86000\n",
      "begin 87000\n",
      "begin 88000\n",
      "begin 89000\n",
      "begin 90000\n",
      "begin 91000\n",
      "begin 92000\n",
      "begin 93000\n",
      "begin 94000\n",
      "begin 95000\n",
      "begin 96000\n",
      "begin 97000\n",
      "begin 98000\n",
      "begin 99000\n",
      "begin 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiyange/anaconda/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1300: RuntimeWarning: init_size=99 should be larger than k=100. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    }
   ],
   "source": [
    "records = {}\n",
    "for n in range(2000, 101000, 1000):\n",
    "    \n",
    "    print ('begin ' + str(n))\n",
    "    sample = n\n",
    "    total = len(X)\n",
    "    subset = X[0::int(total/sample)]\n",
    "\n",
    "    perc=0.0005\n",
    "    batch_size=int(len(subset)*perc)\n",
    "\n",
    "    mbk = MiniBatchKMeans(init='k-means++', n_clusters=100, batch_size=batch_size,\n",
    "                          n_init=10, max_no_improvement=10, verbose=0)\n",
    "    t0 = time.time()\n",
    "    mbk.fit(subset)\n",
    "    t_mini_batch = time.time() - t0\n",
    "    \n",
    "    records[n] = t_mini_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "records_df = pd.DataFrame.from_dict(records, orient = 'index')\n",
    "records_df.to_csv('data/part2_1_a_MiniBatchK_0.0005.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[8,10])\n",
    "ax.scatter(x=list(records.keys()), y=list(records.values()))\n",
    "plt.savefig('part2_1_a_minibatch.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# minibatch kmeans\n",
    "#Number of requested clusters k (consider the range of 2 to the k_max)\n",
    "k_max = 1350\n",
    "records = {}\n",
    "for n in range(2, k_max+1, 100):\n",
    "\n",
    "    perc=0.01\n",
    "    batch_size=int(len(X)*perc)\n",
    "    \n",
    "    mbk = MiniBatchKMeans(init='k-means++', n_clusters=n, batch_size=batch_size,\n",
    "                          n_init=10, max_no_improvement=10, verbose=0)\n",
    "    t0 = time.time()\n",
    "    mbk.fit(X)\n",
    "    t_mini_batch = time.time() - t0\n",
    "    \n",
    "    records[n] = t_mini_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "records_df = pd.DataFrame.from_dict(records, orient = 'index')\n",
    "records_df.to_csv('data/part21MiniBatchKCluster_0.01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[8,10])\n",
    "ax.scatter(x=list(records.keys()), y=list(records.values()))\n",
    "plt.savefig('part2_1_b_minibatch.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recordedtime = {}\n",
    "#ncluster = {}\n",
    "for n in range(100, 100100, 100):\n",
    "    eps=0.001\n",
    "    \n",
    "    sample = n\n",
    "    total = len(X)\n",
    "    subset = X[0::int(total/sample)]\n",
    "    \n",
    "    t_db = time.time()\n",
    "    db = DBSCAN(eps=eps, min_samples=100).fit(subset)\n",
    "    t_fin_db = time.time() - t_db\n",
    "    \n",
    "    recordedtime[n] = t_fin_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recordedtime_df = pd.DataFrame.from_dict(recordedtime, orient = 'index')\n",
    "recordedtime_df.to_csv('data/part2_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[8,10])\n",
    "ax.scatter(x=list(recordedtime.keys()), y=list(recordedtime.values()))\n",
    "plt.savefig('part2_2.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
