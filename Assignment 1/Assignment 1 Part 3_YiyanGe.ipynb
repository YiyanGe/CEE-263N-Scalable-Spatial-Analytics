{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 3. Clustering: 1 million samples problem (40 points). This part deals with the full dataset of 1 million tweets. Your task is to design a system that can handle spatial clustering of 1M samples.\n",
    "Considering the memory limitations and scaling properties of the algorithms studied in Part 2, design the clustering system that can be applied to the full dataset. Consider using a hierarchical approach with two (or more) processing stages, where DBScan is applied to each cluster obtained from a run of mini-batch k-means. By varying the parameters of the algorithms, optimize the processing time required to detect clusters of tweets that correspond to important locations in California. We will consider a location “important” if it is characterized with a cluster’s core of at least 100 samples within a radius of 100 meters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.io\n",
    "import math\n",
    "import json\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/yiyange/Desktop/CE 263N/CEE-263N-Scalable-Spatial-Analytics/Assignment 1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../../data/tweets_1M.json','r') as f:\n",
    "    tweets = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([[tweets[x]['lat'],tweets[x]['lng']] for x in range(0, len(tweets))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def frange(start, stop, step):\n",
    "    i = start\n",
    "    while i < stop:\n",
    "        yield i\n",
    "        i += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import utm\n",
    "for n in range(0, len(X)):\n",
    "    meters = utm.from_latlon(X[n][0],X[n][1])\n",
    "    X[n][0] = meters[0]\n",
    "    X[n][1] = meters[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000.0 64 15.779498100280762\n"
     ]
    }
   ],
   "source": [
    "#corresponds to step 3 in the report\n",
    "for perc in [0.002]:\n",
    "    \n",
    "    for n in range(64, 65):\n",
    "    \n",
    "        batch_size=int(len(X)*perc)\n",
    "        ttl_t = 0\n",
    "\n",
    "        mbk = MiniBatchKMeans(init='k-means++', n_clusters=n, batch_size=batch_size,\n",
    "                              n_init=10, max_no_improvement=10, verbose=0)\n",
    "        t0 = time.time()\n",
    "        mbk.fit(X)\n",
    "        t_mini_batch = time.time() - t0\n",
    "        ttl_t += t_mini_batch\n",
    "\n",
    "        mbk_means_labels = mbk.labels_\n",
    "        mbk_means_cluster_centers = mbk.cluster_centers_\n",
    "        mbk_means_labels_unique = np.unique(mbk_means_labels)\n",
    "\n",
    "        for cluster_label in list(mbk_means_labels_unique):\n",
    "\n",
    "            mask = (mbk_means_labels == cluster_label)\n",
    "            X_cluster = X[mask]\n",
    "\n",
    "            eps = 100\n",
    "            t_db = time.time()\n",
    "            db = DBSCAN(eps=eps, min_samples=100).fit(X_cluster)\n",
    "            t_fin_db = time.time() - t_db\n",
    "\n",
    "            ttl_t += t_fin_db\n",
    "\n",
    "        print (perc*1000000, n, ttl_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#array of numbers, one number represents one cluster\n",
    "db_labels = db.labels_\n",
    "db_labels_unique = set(db_labels)\n",
    "# minus if there are unclustered noises\n",
    "n_clusters_ = len(set(db_labels)) - (1 if -1 in db_labels else 0)\n",
    "#db_labels_unique = np.unique(db_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_clusters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([[tweets[x]['lat'],tweets[x]['lng']] for x in range(0, len(tweets))])\n",
    "\n",
    "# get colors and plot all the points, color-coded by cluster (or gray if not in any cluster, aka noise)\n",
    "fig, ax = plt.subplots(figsize=[8,10])\n",
    "ax.set_xlim([-130, -112])\n",
    "ax.set_ylim([32, 44])\n",
    "colors = plt.cm.rainbow(np.linspace(0, 1, len(db_labels_unique)))\n",
    "\n",
    "# for each cluster label and color, plot the cluster's points\n",
    "for db_label, color in zip(db_labels_unique, colors):\n",
    "    \n",
    "    size = 10\n",
    "    if db_label == -1: #make the noise (which is labeled -1) appear as smaller gray points\n",
    "        color = 'gray'\n",
    "        size = 3\n",
    "        alpha=0.01\n",
    "    \n",
    "    # plot the points that match the current cluster label\n",
    "    x_coords = X[db_labels==db_label][:,1]\n",
    "    y_coords = X[db_labels==db_label][:,0]\n",
    "    ax.scatter(x=x_coords, y=y_coords, c=color, edgecolor='', s=size, alpha=0.5)\n",
    "\n",
    "ax.set_title('Number of clusters: {}'.format(n_clusters_)) #string concatenation\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
